{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham               I HAVE A DATE ON SUNDAY WITH WILL!!!"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and print head of DataFrame\n",
    "df = pd.read_csv(\"spam-data.tsv\", sep=\"\\t\", names=[\"label\", \"message\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5567, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print details about quantity(rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check and remove duplicates\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5164, 2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veryfy how many duplicates have been deleted (rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the number of invalid/missing data (NAN, Nan ..)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Ive been searching for the right words to than...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I dont think he goes to usf he lives aroun...\n",
       "3   ham  Even my brother is not like to speak with me T...\n",
       "4   ham                  I HAVE A DATE ON SUNDAY WITH WILL"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete punctuation\n",
    "df['message'] = df['message'].str.replace('[^\\w\\s]', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ive searching right words thank breather I pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I dont think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even brother like speak They treat like aids p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Ive searching right words thank breather I pro...\n",
       "1  spam  Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "2   ham      Nah I dont think goes usf lives around though\n",
       "3   ham  Even brother like speak They treat like aids p...\n",
       "4   ham                  I HAVE A DATE ON SUNDAY WITH WILL"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['message'] = df['message'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I       1395\n",
       "u        696\n",
       "2        447\n",
       "call     326\n",
       "get      322\n",
       "U        315\n",
       "Im       303\n",
       "4        263\n",
       "ur       255\n",
       "ltgt     254\n",
       "You      246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count frequently used words\n",
    "freq = pd.Series(' '.join(df['message']).split()).value_counts()[:11]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ive searching right words thank breather promi...\n",
       "1    Free entry wkly comp win FA Cup final tkts 21s...\n",
       "2          Nah dont think goes usf lives around though\n",
       "3    Even brother like speak They treat like aids p...\n",
       "4                      HAVE A DATE ON SUNDAY WITH WILL\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete frequently used words\n",
    "df['message'] = df['message'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df['message'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "go      242\n",
       "know    233\n",
       "like    220\n",
       "dont    209\n",
       "got     199\n",
       "come    192\n",
       "time    183\n",
       "day     164\n",
       "want    164\n",
       "lor     157\n",
       "No      156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Re-count frequently used words\n",
    "freq = pd.Series(' '.join(df['message']).split()).value_counts()[:11]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bear           1\n",
       "Caught         1\n",
       "belt           1\n",
       "Aaooooright    1\n",
       "Building       1\n",
       "              ..\n",
       "fgkslpo        1\n",
       "AD             1\n",
       "DIS            1\n",
       "98321561       1\n",
       "DontCha        1\n",
       "Length: 7045, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count rare used words\n",
    "rare = pd.Series(' '.join(df['message']).split()).value_counts()[-7045:]\n",
    "rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ive searching right words thank breather promi...\n",
       "1    Free entry wkly comp win FA Cup final tkts 21s...\n",
       "2          Nah dont think goes usf lives around though\n",
       "3    Even brother like speak They treat like aids p...\n",
       "4                      HAVE A DATE ON SUNDAY WITH WILL\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete rare used words\n",
    "rare = list(rare)\n",
    "df['message'] = df['message'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare))\n",
    "df['message'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DontCha    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Re-count rare used words\n",
    "rare = pd.Series(' '.join(df['message']).split()).value_counts()[-1:]\n",
    "rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Nah', 'dont', 'think', 'goes', 'usf', 'lives', 'around', 'though'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization - split sentence into word list\n",
    "TextBlob(df['message'][2]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorization\n",
    "#Before run download http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#Before run install: conda install -c conda-forge gensim\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization continued\n",
    "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44172 , -0.42239 ,  0.16875 , -0.73071 ,  0.11421 ,  0.58036 ,\n",
       "       -0.15996 , -0.35057 , -0.51585 ,  0.049159,  0.21029 ,  0.33813 ,\n",
       "        0.34015 ,  0.33394 ,  0.43082 , -0.68797 ,  0.016801, -0.4392  ,\n",
       "       -0.63862 ,  0.99979 , -0.22808 , -0.36173 ,  0.26028 ,  0.33471 ,\n",
       "        0.19574 ,  0.1889  , -0.65007 , -0.90396 ,  0.87146 ,  1.0389  ,\n",
       "        0.14813 ,  0.62926 ,  0.45103 ,  0.056848, -0.47635 ,  0.22851 ,\n",
       "        0.019162,  0.23166 ,  0.31517 , -0.04989 , -0.045153,  0.41631 ,\n",
       "        1.2553  , -0.93028 , -0.16085 , -0.0195  , -0.52613 , -0.062153,\n",
       "        0.41316 , -0.23164 , -0.52598 , -0.096949,  0.60631 ,  0.89382 ,\n",
       "        0.24843 , -1.9425  , -1.0757  ,  0.095841, -0.020964,  0.49486 ,\n",
       "        0.36509 ,  0.74831 ,  0.38753 , -0.25084 ,  0.81364 , -0.30012 ,\n",
       "        0.46068 ,  0.76646 , -0.15263 ,  0.83083 , -0.06191 , -0.070126,\n",
       "        0.031228, -0.63841 , -0.15574 ,  0.14927 , -0.11447 , -0.30875 ,\n",
       "       -0.38419 ,  0.12946 ,  0.72202 ,  0.52711 ,  0.12857 , -0.18808 ,\n",
       "       -1.021   , -0.33393 , -0.53043 , -0.63715 , -0.17984 , -0.96474 ,\n",
       "        0.037772, -0.32945 ,  0.78167 ,  0.61159 , -0.71574 , -0.30733 ,\n",
       "       -0.28572 , -0.5258  , -0.21903 , -1.1951  ], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorization - test word\n",
    "model['brother']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5164x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24779 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(df['message'])\n",
    "\n",
    "train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5164x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 30932 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(df['message'])\n",
    "train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ive searching right words thank breather promi...</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nah dont think goes usf lives around though</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even brother like speak They treat like aids p...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  sentiment\n",
       "0  Ive searching right words thank breather promi...   0.642857\n",
       "1  Free entry wkly comp win FA Cup final tkts 21s...   0.300000\n",
       "2        Nah dont think goes usf lives around though   0.000000\n",
       "3  Even brother like speak They treat like aids p...   0.000000\n",
       "4                    HAVE A DATE ON SUNDAY WITH WILL   0.000000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment analysis\n",
    "df['sentiment'] = df['message'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "df[['message','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into 75% training and 25% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_bow, df['message'], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Model - Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Huh means computational science Y like dat one push n'\n",
      " 'sexy sexy cum text im wet warm ready porn fun THIS MSG IS FREE RECD MSGS 150P INC VAT CANCEL TEXT STOP'\n",
      " 'They released vday shirts put makes bottom half naked instead white underwear'\n",
      " ...\n",
      " 'Send logo lover names joined heart Txt LOVE NAME1 NAME2 MOBNO eg LOVE ADAM EVE 07123456789 87077 Yahoo POBox36504W45WQ TxtNO ads 150p'\n",
      " 'Can mag meeting avo point'\n",
      " 'Idk keep saying youre since moved keep butting heads freedom vs responsibility And im tired much shit deal im barely keeping together gets added']\n",
      "['Huh means computational science Y like dat one push n'\n",
      " 'sexy sexy cum text im wet warm ready porn fun THIS MSG IS FREE RECD MSGS 150P INC VAT CANCEL TEXT STOP'\n",
      " 'They released vday shirts put makes bottom half naked instead white underwear'\n",
      " ... 'turns stereo love mi phone unknown album'\n",
      " 'Can mag meeting avo point'\n",
      " 'Idk keep saying youre since moved keep butting heads freedom vs responsibility And im tired much shit deal im barely keeping together gets added']\n"
     ]
    }
   ],
   "source": [
    "#Print the prediction\n",
    "print(classifier.predict(X_train))\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(X_train)\n",
    "#print(classification_report(y_train, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
